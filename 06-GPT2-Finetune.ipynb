{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02-Current-GPT2-Finetune.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw6Oj_4oGguf"
      },
      "source": [
        "# GPT-2 Finetuning\n",
        "\n",
        "Made by [Artem Konevskikh](https://aiculedssul.net/) \n",
        "\n",
        "Based on notebook by [Max Woolf](http://minimaxir.com). For more about `gpt-2-simple`, you can visit [this GitHub repository](https://github.com/minimaxir/gpt-2-simple)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2DuOMM9KKkQ"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEjGHeo1GeCW",
        "cellView": "form"
      },
      "source": [
        "#@title Imports\n",
        "#@markdown By running this cell we are loading libraries needed to work with GPT2\n",
        "!pip install git+https://github.com/minimaxir/gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSFvBs0NIALD",
        "cellView": "form"
      },
      "source": [
        "#@title Downloading GPT-2\n",
        "#@markdown If you're retraining a model on new text, you need to download the GPT-2 model first. \n",
        "\n",
        "#@markdown There are two released sizes of GPT-2 that we can work with in Colab:\n",
        "\n",
        "#@markdown * `124M` (default): the \"small\" model, 500MB on disk.\n",
        "#@markdown * `355M`: the \"medium\" model, 1.5GB on disk.\n",
        "\n",
        "#@markdown Larger model has more knowledge, but takes longer to finetune and longer to generate text. You can specify which base model to use by changing `model_name`.\n",
        "\n",
        "model_name = \"124M\" #@param [\"124M\", \"355M\"] {allow-input: true}\n",
        "\n",
        "#@markdown This cell downloads it from Google Cloud Storage and saves it in the Colaboratory VM at `/models/<model_name>`.\n",
        "\n",
        "#@markdown This model isn't permanently saved in the Colaboratory VM; you'll have to redownload it if you want to retrain it at a later time.\n",
        "\n",
        "\n",
        "gpt2.download_gpt2(model_name=model_name)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPIzR_VlLDEL",
        "cellView": "form"
      },
      "source": [
        "#@title Mounting Google Drive\n",
        "\n",
        "#@markdown Colab notebooks are Virtual Machines, so any data stored in it will be vanished as soon as we close it or reset it. So the best way to keep input data and save trained models is to mount your Google Drive and store it there.\n",
        "\n",
        "#@markdown After running this cell you will get the link, where you should grant the access to your Drive and copy auth token. Paste this token to the input below and press Enter\n",
        "\n",
        "gpt2.mount_gdrive()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPC9ylUAIpV7"
      },
      "source": [
        "### Dataset Text File\n",
        "\n",
        "To finetune GPT2 on your texts you should prepare a single plain text file. Collect the books and articles and copy all of them to this text file.\n",
        "\n",
        "GPT2 works with `.txt` files only, so this link https://www.pdf2go.com/pdf-to-text might be useful if you have your books in `pdf` format.\n",
        "\n",
        "There are two ways to load training data - directly to this notebook or from Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODs12IJPOAYS",
        "cellView": "form"
      },
      "source": [
        "#@title Uploading a Text File directly to Colaboratory\n",
        "\n",
        "#@markdown First way is good if you have file less than 10mb. To upload file go to the Colaboratory Notebook sidebar on the left of the screen, select *Files* (folder icon) and use *Upload* button or drag-n-drop file directly to the files list\n",
        "\n",
        "#@markdown Then copy file path to the input below and run this cell\n",
        "\n",
        "file_name = '/content/bb-vs-ooo.txt' #@param {type: \"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQT0UZuuP1mR",
        "cellView": "form"
      },
      "source": [
        "#@title Uploading a Text File from Google Drive\n",
        "\n",
        "#@markdown Second way is preferable, especially if you have files larger than 10mb. \n",
        "\n",
        "#@markdown Upload file to the Drive, find it in *Files* sidebar, copy file path to the input below and run this cell\n",
        "\n",
        "gdrive_file_name = '/content/drive/MyDrive/medialab/bb-vs-ooo.txt' #@param {type: \"string\"}\n",
        "file_name = gdrive_file_name.split('/')[-1]\n",
        "shutil.copyfile(gdrive_file_name, file_name)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx-ZoN8ePv7c"
      },
      "source": [
        "## Finetune GPT-2\n",
        "\n",
        "The next cell will start the actual finetuning of GPT-2. It creates a persistent TensorFlow session which stores the training config, then runs the training for the specified number of `steps`. (to have the finetuning run indefinitely, set `steps = -1`)\n",
        "\n",
        "The model checkpoints will be saved in `/checkpoint/run1` by default. The checkpoints are saved every 500 steps (can be changed) and when the cell is stopped.\n",
        "\n",
        "The training might time out after 4ish hours; make sure you end training and save the results so you don't lose them!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upQj_LvDRtFU",
        "cellView": "form"
      },
      "source": [
        "#@title Set parameters\n",
        "\n",
        "#@markdown **Model**\n",
        "\n",
        "#@markdown Choose model name you downloaded before\n",
        "model_name=\"124M\" #@param [\"124M\", \"355M\"] {allow-input: true}\n",
        "\n",
        "#@markdown Set to `fresh` to start training from the base GPT-2, or set to `latest` to restart training from an existing checkpoint.\n",
        "restore_from='fresh' #@param [\"fresh\", \"latest\"] {allow-input: true}\n",
        "\n",
        "#@markdown Run name. Subfolder within `checkpoint` to save the model. This is useful if you want to work with multiple models (will also need to specify  `run_name` when loading the model)\n",
        "run_name='gpt-medialab-bbooo' #@param {type: \"string\"}\n",
        "\n",
        "#@markdown **Steps**\n",
        "\n",
        "#@markdown Number of steps to train the model.\n",
        "steps=200 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown Number of steps to print example output\n",
        "sample_every=30 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown Number of steps to save the model.\n",
        "save_every=50 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown Number of steps to print training progress.\n",
        "print_every=10 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown **Other**\n",
        "\n",
        "#@markdown Learning rate for the training. (default `1e-4`, can lower to `1e-5` if you have <1MB input data)\n",
        "learning_rate=0.000055 #@param {type:\"slider\", min:1e-5, max:1e-4, step:4.5e-5}\n",
        "\n",
        "#@markdown Check if you want to continue finetuning an existing model (w/ `restore_from='latest'`) without creating duplicate copies. \n",
        "overwrite=False #@param {type: \"boolean\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN72iY8QXONA",
        "cellView": "form"
      },
      "source": [
        "#@title Run finetuning\n",
        "#@markdown **IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports and settings but not recopy files.\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name=model_name,\n",
        "              steps=steps,\n",
        "              restore_from=restore_from,\n",
        "              run_name=run_name,\n",
        "              print_every=print_every,\n",
        "              sample_every=sample_every,\n",
        "              save_every=save_every,\n",
        "              learning_rate=learning_rate,\n",
        "              overwrite=overwrite,\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hMiXdVmYFVS",
        "cellView": "form"
      },
      "source": [
        "#@title Save results\n",
        "\n",
        "#@markdown By running this cell the checkpoint folder will be copied as a *.rar* compressed file to your own Google Drive.\n",
        "\n",
        "#@markdown You can use this file later to generate text.\n",
        "\n",
        "gpt2.copy_checkpoint_to_gdrive(run_name=run_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhNS2YrcZNQ9"
      },
      "source": [
        "## That's all! Now we can generate the text!"
      ]
    }
  ]
}