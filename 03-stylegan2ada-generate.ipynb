{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03-stylegan2ada-generate.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XH5qhxBngNpc"
      },
      "source": [
        "# StyleGAN2 ADA PyTorch Generation\n",
        "\n",
        "Made by [Artem Konevskikh](https://aiculedssul.net/)\n",
        "\n",
        "Based on [dvschultz notebooks](https://github.com/dvschultz/ml-art-colabs)\n",
        "\n",
        "Some pretrained models can be found [here](https://github.com/justinpinkney/awesome-pretrained-stylegan2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install required libraries\n",
        "!pip install ninja opensimplex numpy==1.21.6"
      ],
      "metadata": {
        "cellView": "form",
        "id": "-6RJuEczrQre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "T1X9H9xXgMdg"
      },
      "source": [
        "#@title Mount Google Drive\n",
        "#@markdown Mount Google Drive to load pretrained models and to save the results.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7PeyWJfgjob",
        "cellView": "form"
      },
      "source": [
        "#@title Install Stylegan2-ada\n",
        "#@markdown StyleGAN2-ada will be installed to your Google Drive to speed up the training process\n",
        "\n",
        "#@markdown Run this cell. If you’re already installed the repo, it will skip the installation process and change into the repo’s directory. If you haven’t installed it, it will install all the files necessary.\n",
        "import os\n",
        "import shlex\n",
        "import numpy as np\n",
        "\n",
        "if os.path.isdir(\"/content/drive/MyDrive/stylegan2ada\"):\n",
        "    %cd \"/content/drive/MyDrive/stylegan2ada/stylegan2-ada-pytorch\"\n",
        "elif os.path.isdir(\"/content/drive/\"):\n",
        "    #install script\n",
        "    %cd \"/content/drive/MyDrive/\"\n",
        "    !mkdir stylegan2ada\n",
        "    %cd stylegan2ada\n",
        "    !git clone https://github.com/artem-konevskikh/stylegan2-ada-pytorch.git\n",
        "    %cd stylegan2-ada-pytorch\n",
        "    !mkdir downloads\n",
        "    !mkdir datasets\n",
        "    # !mkdir pretrained\n",
        "    # !gdown --id 1-5xZkD8ajXw1DdopTkH_rAoCsD72LhKU -O /content/drive/MyDrive/stylegan2ada/stylegan2-ada-pytorch/pretrained/wikiart.pkl\n",
        "else:\n",
        "    !git clone https://github.com/artem-konevskikh/stylegan2-ada-pytorch.git\n",
        "    %cd stylegan2-ada-pytorch\n",
        "    !mkdir downloads\n",
        "    !mkdir datasets\n",
        "    !mkdir pretrained\n",
        "    %cd pretrained\n",
        "    !gdown --id 1-5xZkD8ajXw1DdopTkH_rAoCsD72LhKU\n",
        "    %cd ../\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Convert Legacy Model\n",
        "\n",
        "#@markdown If you have an older version of a model (Tensorflow based StyleGAN, or Runway downloaded .pkl file) you’ll need to convert to the newest version. If you’ve trained in this workshop you do **not** need to use this cell.\n",
        "\n",
        "#@markdown Path to model that you want to convert \n",
        "source_pkl = \"\" #@param {type: \"string\"}\n",
        "#@markdown Path and file name to convert to.\n",
        "dest_pkl = \"\" #@param {type: \"string\"}\n",
        "\n",
        "source_pkl = shlex.quote(source_pkl)\n",
        "dest_pkl = shlex.quote(dest_pkl)\n",
        "!python legacy.py --source={source_pkl} --dest={dest_pkl}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HKhBq1rM781u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Pretrained Model\n",
        "#@markdown This will download the model trained on 1024x1024 faces from FFHQ Dataset\n",
        "!wget -O /content/ffhq.pkl https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/ffhq.pkl"
      ],
      "metadata": {
        "cellView": "form",
        "id": "N2onahdm1arr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "el28DuPKmQ9P"
      },
      "source": [
        "# Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNaj42CuwG06",
        "cellView": "form"
      },
      "source": [
        "#@title Generate Images\n",
        "#@markdown Directory to save the generated images\n",
        "outdir = \"/content/drive/MyDrive/stylegan/results/2023-01-17\" #@param {type: \"string\"}\n",
        "#@markdown Path to the pretrained model. The most accurate way is to right click on the file in the Files pane to your left and choose `Copy Path`, then paste that here\n",
        "network = \"/content/drive/MyDrive/stylegan2ada/stylegan2-ada-pytorch/results/00001-maria2-11gb-gpu-noaug-resumecustom/network-snapshot-000004.pkl\" #@param {type: \"string\"}\n",
        "#@markdown ---\n",
        "#@markdown **Generation Parameters**\n",
        "\n",
        "#@markdown Truncation, well, truncates the latent space. This can have a subtle or dramatic affect on your images depending on the value you use. The smaller the number the more realistic your images should appear, but this will also affect diversity. Most people choose between 0.5 and 1.0, but technically it's infinite. \n",
        "truncation = 0.8 #@param {type: \"number\"}\n",
        "#@markdown This allows you to choose random seeds from the model. Remember that our input to StyleGAN is a 512-dimensional array. These seeds will generate those 512 values. Each seed will generate a different, random array. The same seed value will also always generate the same random array, so we can later use it for other purposes like interpolation. Provide one number or comma-separated list of integers\n",
        "seeds = \"42,3333,80\" #@param {type: \"string\"}\n",
        "#@markdown Generate random images (`seeds` parameter will be ignored)\n",
        "gen_random = True #@param {type: \"boolean\"}\n",
        "#@markdown Amount of random images to generate\n",
        "n_imgs =  200#@param {type: \"integer\"}\n",
        "#@markdown ---\n",
        "#@markdown **Generate Non-Square Images**\n",
        "\n",
        "#@markdown It's possible to make the model to output images that are not square. This isn’t as good as training a rectangular model, but with the right model it can still look nice.\n",
        "gen_nonsquare = False #@param {type: \"boolean\"}\n",
        "#@markdown Width\n",
        "width = 1920 #@param {type: \"integer\"}\n",
        "#@markdown Height\n",
        "height = 1080 #@param {type: \"integer\"}\n",
        "#@markdown Padding style to apply in the additional space\n",
        "scale_type = 'pad' #@param ['pad', 'padside', 'symm', 'symmside']\n",
        "\n",
        "\n",
        "if gen_random:\n",
        "  seeds = ','.join(str(s) for s in list(set(list(np.random.randint(4294967295, size=n_imgs)))))\n",
        "else:\n",
        "  seeds = ','.join(str(s).strip() for s in seeds.split(','))\n",
        "print(\"Seeds: \", seeds)\n",
        "\n",
        "nonsquare = f'--size={width}-{height} --scale-type={scale_type}' if gen_nonsquare else ''\n",
        "\n",
        "\n",
        "outdir = shlex.quote(outdir)\n",
        "network = shlex.quote(network)\n",
        "!python generate.py --outdir={outdir} --trunc={truncation} --seeds={seeds} --network={network} {nonsquare}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEEr74W333U2",
        "cellView": "form"
      },
      "source": [
        "#@title Truncation Traversal\n",
        "\n",
        "#@markdown Below you can take one seed and look at the changes to it across any truncation amount. -1 to 1 will be pretty realistic images, but the further out you get the weirder it gets.\n",
        "\n",
        "#@markdown Directory to save the generated images\n",
        "outdir = \"/content/drive/MyDrive/workshops/digitalfutures/results/2\" #@param {type: \"string\"}\n",
        "#@markdown Path to the pretrained model. The most accurate way is to right click on the file in the Files pane to your left and choose `Copy Path`, then paste that here\n",
        "network = \"/content/drive/MyDrive/workshops/digitalfutures/wood-clt-200.pkl\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown Pass this only one seed. Pick a favorite from your generated images.\n",
        "seed = 42  #@param {type: \"integer\"}\n",
        "#@markdown Starting truncation value.\n",
        "start = -1  #@param {type: \"number\"}\n",
        "#@markdown Stopping truncation value. This should be larger than the start value. (Will probably break if its not).\n",
        "stop = 1  #@param {type: \"number\"}\n",
        "#@markdown How much each frame should increment the truncation value. Make this really small if you want a long, slow interpolation. (stop-start/increment=total frames)\n",
        "increment = 0.01  #@param {type: \"number\"}\n",
        "\n",
        "outdir = shlex.quote(outdir)\n",
        "network = shlex.quote(network)\n",
        "!python generate.py --process=\"truncation\" --outdir={outdir} --start={start} --stop={stop} --increment={increment} --seeds={seed} --network={network}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGZVg1JxlPyZ",
        "cellView": "form"
      },
      "source": [
        "#@title Interpolation\n",
        "#@markdown Directory to save the generated images\n",
        "outdir = \"/content/drive/MyDrive/stylegan2ada/results/interpolation-test\" #@param {type: \"string\"}\n",
        "#@markdown Path to the pretrained model. The most accurate way is to right click on the file in the Files pane to your left and choose `Copy Path`, then paste that here\n",
        "network = \"/content/drive/MyDrive/stylegan2ada/wood-clr-40.pkl\" #@param {type: \"string\"}\n",
        "#@markdown ---\n",
        "#@markdown **Generation Parameters**\n",
        "\n",
        "#@markdown Truncation, well, truncates the latent space. This can have a subtle or dramatic affect on your images depending on the value you use. The smaller the number the more realistic your images should appear, but this will also affect diversity. Most people choose between 0.5 and 1.0, but technically it's infinite. \n",
        "truncation = 0.8 #@param {type: \"number\"}\n",
        "#@markdown This allows you to choose random seeds from the model. Remember that our input to StyleGAN is a 512-dimensional array. These seeds will generate those 512 values. Each seed will generate a different, random array. The same seed value will also always generate the same random array, so we can later use it for other purposes like interpolation. Provide one number or comma-separated list of integers\n",
        "seeds = \"42,333\" #@param {type: \"string\"}\n",
        "#@markdown Generate random images (`seeds` parameter will be ignored)\n",
        "gen_random = True #@param {type: \"boolean\"}\n",
        "#@markdown Amount of random images to generate\n",
        "n_imgs = 5 #@param {type: \"integer\"}\n",
        "#@markdown Loop interpolation\n",
        "gen_loop = True #@param {type: \"boolean\"}\n",
        "#@markdown ---\n",
        "#@markdown **Interpolation Parameters**\n",
        "\n",
        "#@markdown Interpolation type\n",
        "interpolation = 'linear' #@param ['linear', 'slerp']\n",
        "#@markdown Latent space\n",
        "space = 'z' #@param ['z', 'w']\n",
        "#@markdown Interpolation steps. How many frames to produce\n",
        "steps=60 #@param {type: \"integer\"}\n",
        "#@markdown FPS, video framerate\n",
        "fps=48 #@param {type: \"integer\"}\n",
        "#@markdown ---\n",
        "#@markdown **Generate Non-Square Images**\n",
        "\n",
        "#@markdown It's possible to make the model to output images that are not square. This isn’t as good as training a rectangular model, but with the right model it can still look nice.\n",
        "gen_nonsquare = False #@param {type: \"boolean\"}\n",
        "#@markdown Width\n",
        "width = 1920 #@param {type: \"integer\"}\n",
        "#@markdown Height\n",
        "height = 1080 #@param {type: \"integer\"}\n",
        "#@markdown Padding style to apply in the additional space\n",
        "scale_type = 'pad' #@param ['pad', 'padside', 'symm', 'symmside']\n",
        "\n",
        "\n",
        "if gen_random:\n",
        "  seeds = list(set(list(np.random.randint(4294967295, size=n_imgs))))\n",
        "  if gen_loop:\n",
        "    seeds.append(seeds[-1])\n",
        "  seeds = ','.join(str(s) for s in seeds)\n",
        "else:\n",
        "  seeds = ','.join(str(s).strip() for s in seeds.split(','))\n",
        "print(\"Seeds: \", seeds)\n",
        "\n",
        "nonsquare = f'--size={width}-{height} --scale-type={scale_type}' if gen_nonsquare else ''\n",
        "\n",
        "outdir = shlex.quote(outdir)\n",
        "network = shlex.quote(network)\n",
        "!python generate.py --outdir={outdir} --trunc={truncation} --seeds={seeds} --network={network} {nonsquare} --space={space} --process=\"interpolation\" --interpolation={interpolation} --frames={steps} --fps={fps}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCbgH771qK_w",
        "cellView": "form"
      },
      "source": [
        "#@title Interpolation loops\n",
        "#@markdown Directory to save the generated images\n",
        "outdir = \"/content/drive/MyDrive/stylegan/results/2021-09-03\" #@param {type: \"string\"}\n",
        "#@markdown Path to the pretrained model. The most accurate way is to right click on the file in the Files pane to your left and choose `Copy Path`, then paste that here\n",
        "network = \"/content/drive/MyDrive/stylegan2ada/stylegan2-ada-pytorch/results/00001-maria2-11gb-gpu-noaug-resumecustom/network-snapshot-000004.pkl\" #@param {type: \"string\"}\n",
        "#@markdown ---\n",
        "#@markdown **Generation Parameters**\n",
        "\n",
        "#@markdown Truncation, well, truncates the latent space. This can have a subtle or dramatic affect on your images depending on the value you use. The smaller the number the more realistic your images should appear, but this will also affect diversity. Most people choose between 0.5 and 1.0, but technically it's infinite. \n",
        "truncation = 1 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **Interpolation Parameters**\n",
        "\n",
        "#@markdown Interpolation type\n",
        "interpolation = 'circularloop' #@param ['noiseloop', 'circularloop']\n",
        "#@markdown Number of frames\n",
        "frames = 1440 #@param {type: \"integer\"}\n",
        "#@markdown This controls how \"wide\" the loop is. Make it smaller to show a less diverse range of samples. Make it larger to cover a lot of samples. This plus `frames` can help determine how fast the video feels.\n",
        "diameter = 900 #@param {type: \"number\"}\n",
        "#@markdown FPS, video framerate\n",
        "fps=24 #@param {type: \"integer\"}\n",
        "#@markdown Starting place in the z space. Note: this value has nothing to do with the seeds you use to generate images. It just allows you to randomize your start point\n",
        "random_seed = 42 #@param {type: \"integer\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **Generate Non-Square Images**\n",
        "\n",
        "#@markdown It's possible to make the model to output images that are not square. This isn’t as good as training a rectangular model, but with the right model it can still look nice.\n",
        "gen_nonsquare = True #@param {type: \"boolean\"}\n",
        "#@markdown Width\n",
        "width = 1920 #@param {type: \"integer\"}\n",
        "#@markdown Height\n",
        "height = 1080 #@param {type: \"integer\"}\n",
        "#@markdown Padding style to apply in the additional space\n",
        "scale_type = 'pad' #@param ['pad', 'padside', 'symm', 'symmside']\n",
        "\n",
        "\n",
        "nonsquare = f'--size={width}-{height} --scale-type={scale_type}' if gen_nonsquare else ''\n",
        "\n",
        "outdir = shlex.quote(outdir)\n",
        "network = shlex.quote(network)\n",
        "!python generate.py --outdir={outdir} --trunc={truncation} --network={network} {nonsquare} --process=\"interpolation\" --interpolation={interpolation} --diameter={diameter} --random_seed={random_seed} --frames={frames} --fps={fps}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Flesh Digressions\n",
        "\n",
        "#@markdown Producing Videos from circular loops of the constant and latent layers in StyleGAN2\n",
        "#@markdown A .pkl of a StyleGAN network model\n",
        "network = \"/content/drive/MyDrive/stylegan2ada/stylegan2-ada-pytorch/results/00001-maria2-11gb-gpu-noaug-resumecustom/network-snapshot-000004.pkl\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown The truncation psi used in the generator\n",
        "truncation = 1 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown The radius for the constant layer interpolation\n",
        "radius_large=300.0 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown The radius for the latent space interpolation\n",
        "radius_small=40.0 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown The value of the step/increment for the constant layer interpolation\n",
        "step1=0.005 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown The value of the step/increment for the latent space interpolation\n",
        "step2=0.0025 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown The length of the video in terms of circular interpolation, ex. default is 1.0, step2 is 0.0025, so video length is 400 frames. Recommended to keep at 1.0\n",
        "video_length=1.0 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown It's possible to make the model to output images that are not square. This isn’t as good as training a rectangular model, but with the right model it can still look nice.\n",
        "gen_nonsquare = True #@param {type: \"boolean\"}\n",
        "#@markdown Width\n",
        "width = 1920 #@param {type: \"integer\"}\n",
        "#@markdown Height\n",
        "height = 1080 #@param {type: \"integer\"}\n",
        "#@markdown Padding style to apply in the additional space\n",
        "scale_type = 'pad' #@param ['pad', 'padside', 'symm', 'symmside']\n",
        "\n",
        "\n",
        "nonsquare = f'--size={width}-{height} --scale-type={scale_type}' if gen_nonsquare else ''\n",
        "network = shlex.quote(network)\n",
        "\n",
        "!python flesh_digression.py --pkl $network --psi=$truncation --radius_small=$radius_small --radius_large=$radius_large --step1=$step1  --step2=$step2 $nonsquare"
      ],
      "metadata": {
        "cellView": "form",
        "id": "bsJbDVi7GCWj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}