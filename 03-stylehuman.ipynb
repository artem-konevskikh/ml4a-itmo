{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03-stylehuman.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# StyleGAN Human\n",
        "\n",
        "Made by [Artem Konevskikh](https://aiculedssul.net/)\n",
        "\n",
        "Based on [StyleGAN-Human](https://github.com/stylegan-human/StyleGAN-Human)"
      ],
      "metadata": {
        "id": "hdFOGn9KDLRs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "w1IDblAjLc6k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FttftEJeDKjn"
      },
      "outputs": [],
      "source": [
        "#@title GPU Check\n",
        "#@markdown You can check which GPU you got. V100 is perfect, P100 and T4 is good, but if you got K80 its better to restart the notebook by selecting **Disconnect and delete runtime** in **Runtime** menu, because it is very slow\n",
        "!nvidia-smi -L\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount Google Drive\n",
        "#@markdown Mount Google Drive to load pretrained models and to save the results.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SLthoy67DzPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install\n",
        "!git clone https://github.com/stylegan-human/StyleGAN-Human.git\n",
        "\n",
        "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
        "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
        "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force \n",
        "\n",
        "!pip install lpips\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Fhe0WYyUD3RS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load libraries\n",
        "# %tensorflow_version 1.x \n",
        "import os\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import shlex"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XYRhI8c8KtmL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download models\n",
        "\n",
        "repo_name='StyleGAN-Human'\n",
        "os.chdir(f'/content/{repo_name}')\n",
        "\n",
        "def get_download_model_command(file_id, file_name):\n",
        "    \"\"\" Get wget download command for downloading the desired model and save to directory ../pretrained_models. \"\"\"\n",
        "    save_path = os.path.join('/content/', f'{repo_name}',\"pretrained_models\")\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "    url = r\"\"\"wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id={FILE_ID}' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id={FILE_ID}\" -O {SAVE_PATH}/{FILE_NAME} && rm -rf /tmp/cookies.txt\"\"\".format(FILE_ID=file_id, FILE_NAME=file_name, SAVE_PATH=save_path)\n",
        "    return url\n",
        "\n",
        "MODEL_PATHS = {\n",
        "    \"stylegan1_1024\": {\"id\": \"1h-R-IV-INGdPEzj4P9ml6JTEvihuNgLX\", \"name\": \"stylegan1_1024.pkl\"},\n",
        "    \"stylegan2_1024\": {\"id\": \"1FlAb1rYa0r_--Zj_ML8e6shmaF28hQb5\", \"name\": \"stylegan2_1024.pkl\"},\n",
        "    \"stylegan2_512\": {\"id\": \"1dlFEHbu-WzQWJl7nBBZYcTyo000H9hVm\", \"name\": \"stylegan2_512.pkl\"},\n",
        "    \"stylegan3_512\": {\"id\": \"1_274jk_N6WSCkKWeu7hjHycqGvbuOFf5\", \"name\": \"stylegan3_512.pkl\"},\n",
        "}\n",
        "for model, params in MODEL_PATHS.items():\n",
        "  download_command = get_download_model_command(file_id=params[\"id\"], file_name=params[\"name\"])\n",
        "  !{download_command}\n",
        "\n",
        "ffhq_ckpt = get_download_model_command(file_id=\"125OG7SMkXI-Kf2aqiwLLHyCvSW-gZk3M\", file_name='ffhq.pkl')\n",
        "!{ffhq_ckpt}\n",
        "dlib_detector = get_download_model_command(file_id=\"1MduBgju5KFNrQfDLoQXJ_1_h5MnctCIG\", file_name='mmod_human_face_detector.dat')\n",
        "!{dlib_detector}\n",
        "dlib_landmark = get_download_model_command(file_id=\"1A82DnJBJzt8wI2J8ZrCK5fgHcQ2-tcWM\", file_name='shape_predictor_68_face_landmarks.dat')\n",
        "!{dlib_landmark}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vqw7KQy7J997"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate"
      ],
      "metadata": {
        "id": "LRiugu-2LNuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate full-body images\n",
        "\n",
        "#@markdown Select model\n",
        "experiment_type = 'stylegan2_1024' #@param ['stylegan1_1024', 'stylegan2_1024', 'stylegan2_512', 'stylegan3_512']\n",
        "#@markdown Directory to save the generated images\n",
        "outdir = \"/content/results/1\" #@param {type: \"string\"}\n",
        "#@markdown Truncation, well, truncates the latent space. This can have a subtle or dramatic affect on your images depending on the value you use. The smaller the number the more realistic your images should appear, but this will also affect diversity. Most people choose between 0.5 and 1.0, but technically it's infinite. \n",
        "truncation = 0.8 #@param {type: \"number\"}\n",
        "#@markdown This allows you to choose random seeds from the model. Remember that our input to StyleGAN is a 512-dimensional array. These seeds will generate those 512 values. Each seed will generate a different, random array. The same seed value will also always generate the same random array, so we can later use it for other purposes like interpolation. Provide one number, range or comma-separated list of integers\n",
        "seeds = \"42,333\" #@param {type: \"string\"}\n",
        "\n",
        "version=experiment_type.split(\"_\")[0][-1]\n",
        "outdir = shlex.quote(outdir)\n",
        "!python generate.py --outdir={outdir} --seeds={seeds} --trunc={truncation} --network=/content/StyleGAN-Human/pretrained_models/{experiment_type}.pkl --version {version}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "rDcKORhvLxnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Visualize\n",
        "output_images = [os.path.join(f\"{outdir}\", x) for x in os.listdir(f\"{outdir}\")]\n",
        "for idx, image_path in enumerate(output_images):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    if idx == 0:\n",
        "        res = image\n",
        "    else:\n",
        "        res = np.concatenate([res, image], axis=1)\n",
        "\n",
        "res = Image.fromarray(res)\n",
        "res"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4fWSVTGIOhG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Interpolation\n",
        "#@markdown Select model\n",
        "experiment_type = 'stylegan2_1024' #@param ['stylegan1_1024', 'stylegan2_1024', 'stylegan2_512', 'stylegan3_512']\n",
        "#@markdown Directory to save the generated images\n",
        "outdir = \"/content/results/2\" #@param {type: \"string\"}\n",
        "#@markdown Truncation, well, truncates the latent space. This can have a subtle or dramatic affect on your images depending on the value you use. The smaller the number the more realistic your images should appear, but this will also affect diversity. Most people choose between 0.5 and 1.0, but technically it's infinite. \n",
        "truncation = 0.8 #@param {type: \"number\"}\n",
        "#@markdown This allows you to choose random seeds from the model. Remember that our input to StyleGAN is a 512-dimensional array. These seeds will generate those 512 values. Each seed will generate a different, random array. The same seed value will also always generate the same random array, so we can later use it for other purposes like interpolation. Provide one number, range or comma-separated list of integers\n",
        "seeds = \"42,333\" #@param {type: \"string\"}\n",
        "#@markdown Number of interpolation images\n",
        "num_interps = 100 #@param {type: \"integer\"}\n",
        "#@markdown FPS\n",
        "fps = 10 #@param {type: \"integer\"}\n",
        "\n",
        "outdir = shlex.quote(outdir)\n",
        "!python interpolation.py --outdir={outdir} --seeds={seeds} --trunc={truncation} --network=/content/StyleGAN-Human/pretrained_models/{experiment_type}.pkl --fps={fps} --num_interps={num_interps}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "jVyMJSaYPylq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Editing\n",
        "#@markdown Select model\n",
        "experiment_type = 'stylegan2_1024' #@param ['stylegan1_1024', 'stylegan2_1024', 'stylegan2_512', 'stylegan3_512']\n",
        "#@markdown Directory to save the generated images\n",
        "outdir = \"/content/results/3\" #@param {type: \"string\"}\n",
        "#@markdown Truncation, well, truncates the latent space. This can have a subtle or dramatic affect on your images depending on the value you use. The smaller the number the more realistic your images should appear, but this will also affect diversity. Most people choose between 0.5 and 1.0, but technically it's infinite. \n",
        "truncation = 0.8 #@param {type: \"number\"}\n",
        "#@markdown This allows you to choose random seeds from the model. Remember that our input to StyleGAN is a 512-dimensional array. These seeds will generate those 512 values. Each seed will generate a different, random array. The same seed value will also always generate the same random array, so we can later use it for other purposes like interpolation. Provide one number, range or comma-separated list of integers\n",
        "seeds = \"42,420\" #@param {type: \"string\"}\n",
        "#@markdown Attribute\n",
        "attr_name = 'bottom_length'  #@param ['upper_length', 'bottom_length']\n",
        "\n",
        "outdir = shlex.quote(outdir)\n",
        "!python edit.py --outdir={outdir} --seeds={seeds} --trunc={truncation} --network=/content/StyleGAN-Human/pretrained_models/{experiment_type}.pkl --attr_name {attr_name}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "2zNBamHBPQOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Style-mixing\n",
        "#@markdown Select model\n",
        "experiment_type = 'stylegan2_1024' #@param ['stylegan1_1024', 'stylegan2_1024', 'stylegan2_512', 'stylegan3_512']\n",
        "#@markdown Directory to save the generated images\n",
        "outdir = \"/content/results/4\" #@param {type: \"string\"}\n",
        "#@markdown Truncation, well, truncates the latent space. This can have a subtle or dramatic affect on your images depending on the value you use. The smaller the number the more realistic your images should appear, but this will also affect diversity. Most people choose between 0.5 and 1.0, but technically it's infinite. \n",
        "truncation = 0.8 #@param {type: \"number\"}\n",
        "#@markdown Random seeds to use for image rows\n",
        "rows = \"42,333\" #@param {type: \"string\"}\n",
        "#@markdown Random seeds to use for image columns\n",
        "cols = \"23,420\" #@param {type: \"string\"}\n",
        "#@markdown Style layer range (from 0 to 12?)\n",
        "styles = \"0-6\" #@param {type: \"string\"}\n",
        "\n",
        "outdir = shlex.quote(outdir)\n",
        "!python style_mixing.py --outdir={outdir} --trunc={truncation} --network=/content/StyleGAN-Human/pretrained_models/{experiment_type}.pkl --rows={rows} --cols={cols} --styles={styles}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Q83EirStSQM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Style-mixing video\n",
        "#@markdown Select model\n",
        "experiment_type = 'stylegan2_1024' #@param ['stylegan1_1024', 'stylegan2_1024', 'stylegan2_512', 'stylegan3_512']\n",
        "#@markdown Directory to save the generated images\n",
        "outdir = \"/content/results/5\" #@param {type: \"string\"}\n",
        "#@markdown Truncation, well, truncates the latent space. This can have a subtle or dramatic affect on your images depending on the value you use. The smaller the number the more realistic your images should appear, but this will also affect diversity. Most people choose between 0.5 and 1.0, but technically it's infinite. \n",
        "truncation = 0.8 #@param {type: \"number\"}\n",
        "#@markdown Random seeds to use for image rows\n",
        "row = 42 #@param {type: \"integer\"}\n",
        "#@markdown Random seeds to use for image columns\n",
        "cols = \"23,420\" #@param {type: \"string\"}\n",
        "#@markdown Style layer range (from 0 to 12?)\n",
        "styles = \"0-3\" #@param {type: \"string\"}\n",
        "#@markdown Duration\n",
        "duration = 10 #@param {type: \"integer\"}\n",
        "#@markdown FPS\n",
        "fps = 10 #@param {type: \"integer\"}\n",
        "\n",
        "outdir = shlex.quote(outdir)\n",
        "!python stylemixing_video.py --outdir={outdir} --trunc={truncation} --network=/content/StyleGAN-Human/pretrained_models/{experiment_type}.pkl --row-seed={row} --col-seeds={cols} --col-styles={styles} --duration-sec={duration} --fps={fps} "
      ],
      "metadata": {
        "cellView": "form",
        "id": "Iq6LNVPuU9Mp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title InsetGAN (use StyleGAN2-FFHQ as face generator)\n",
        "\n",
        "#@markdown Select model\n",
        "experiment_type = 'stylegan2_1024' #@param ['stylegan1_1024', 'stylegan2_1024', 'stylegan2_512', 'stylegan3_512']\n",
        "#@markdown Directory to save the generated images (should be relative path)\n",
        "outdir = \"../../content/results/6\" #@param {type: \"string\"}\n",
        "#@markdown Truncation, well, truncates the latent space. This can have a subtle or dramatic affect on your images depending on the value you use. The smaller the number the more realistic your images should appear, but this will also affect diversity. Most people choose between 0.5 and 1.0, but technically it's infinite. \n",
        "truncation = 0.8 #@param {type: \"number\"}\n",
        "#@markdown Face seed\n",
        "face_seed = 9 #@param {type: \"integer\"}\n",
        "#@markdown Body seed\n",
        "body_seed = 333 #@param {type: \"integer\"}\n",
        "#@markdown Number of steps for joint optimization\n",
        "joint_steps = 500 #@param {type: \"integer\"}\n",
        "#@markdown Save video\n",
        "video = True #@param {type: \"boolean\"}\n",
        "\n",
        "video = int(video)\n",
        "outdir = shlex.quote(outdir)\n",
        "!python insetgan.py --face_seed={face_seed} --body_seed={body_seed} \\\n",
        "                    --joint_steps={joint_steps} --video {video} \\\n",
        "                    --trunc={truncation} --outdir={outdir} \\\n",
        "                    --body_network=/content/StyleGAN-Human/pretrained_models/{experiment_type}.pkl"
      ],
      "metadata": {
        "cellView": "form",
        "id": "y4haaVGKXmbl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}