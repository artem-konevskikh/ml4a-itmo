{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06-transformers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# HuggingFace Transformers\n",
        "\n",
        "Solving tiypical Natural Language Processing tasks with Transformers\n",
        "\n",
        "Made by [Artem Konevskikh](https://aiculedssul.net/)"
      ],
      "metadata": {
        "id": "VeivLANUlBAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install\n",
        "!pip install transformers\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "\n",
        "from google.colab import data_table\n",
        "from IPython.display import clear_output \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data_table.enable_dataframe_formatter()\n",
        "\n",
        "DEVICE = torch.device(\"cuda:0\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EgHnpUEulP0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Typical NLP tasks"
      ],
      "metadata": {
        "id": "htAEMC-GBUbW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xhBA9jg5k_xO"
      },
      "outputs": [],
      "source": [
        "#@title Named Entity Recognition\n",
        "#@markdown Named Entity Recognition (NER) is the task of classifying tokens according to a class, for example, identifying a token as a person, an organisation or a location.\n",
        "ner_pipe = pipeline(\"ner\", aggregation_strategy=\"simple\", use_fast=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **Find all entities**\n",
        "text = \"Timothy Bloxam Morton (born 19 June 1968) is a professor and Rita Shea Guffey Chair in English at Rice University.\"  #@param {type:\"string\"}\n",
        "is_textfile = False  #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "if is_textfile:\n",
        "  if os.path.isfile(text):\n",
        "    with open(text, \"r\") as f:\n",
        "      sequence = f.read()\n",
        "else:\n",
        "  sequence = text\n",
        "\n",
        "entities = ner_pipe(sequence)\n",
        "df_entities = pd.DataFrame(entities)\n",
        "df_entities"
      ],
      "metadata": {
        "cellView": "form",
        "id": "g4Qh7GtXwOpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **Print etities of certain type**\n",
        "entity_dict = {\n",
        "  \"Person\": \"PER\", \n",
        "  \"Organization\": \"ORG\", \n",
        "  \"Location\": \"LOC\", \n",
        "  \"Miscellaneous\": \"MISC\"\n",
        "}\n",
        "entity_group = 'Organization' #@param [\"Person\", \"Organization\", \"Location\", \"Miscellaneous\"]\n",
        "for entity in entities:\n",
        "  if entity[\"entity_group\"] == entity_dict[entity_group]:\n",
        "    print(entity[\"word\"])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "u5K-BH0RwzxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Classification\n",
        "#@markdown **Sentiment Analysis**: Identifying if a text is positive or negative\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "CwqOdqX5lSMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Timothy Bloxam Morton (born 19 June 1968) is a professor and Rita Shea Guffey Chair in English at Rice University.\"  #@param {type:\"string\"}\n",
        "is_textfile = False  #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "if is_textfile:\n",
        "  if os.path.isfile(text):\n",
        "    with open(text, \"r\") as f:\n",
        "      sequence = f.read()\n",
        "else:\n",
        "  sequence = text\n",
        "\n",
        "sent = classifier(sequence)\n",
        "print(f\"Text is {sent[0]['label']}, with score: {round(sent[0]['score']*100, 2)}%\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hVDyKm8R2ALH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Summarization\n",
        "#@markdown Summarization is the task of summarizing a document or an article into a shorter text. \n",
        "summarizer = pipeline(\"summarization\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fxkQEeTknWRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **Summarize**\n",
        "text = \"/content/ooo.txt\"  #@param {type:\"string\"}\n",
        "is_textfile = True  #@param {type:\"boolean\"}\n",
        "min_length = 30 #@param {type:\"integer\"}\n",
        "max_length = 40 #@param {type:\"integer\"}\n",
        "\n",
        "if is_textfile:\n",
        "  if os.path.isfile(text):\n",
        "    with open(text, \"r\") as f:\n",
        "      sequence = f.read()\n",
        "else:\n",
        "  sequence = text\n",
        "\n",
        "summary = summarizer(sequence[:4096], max_length=max_length, min_length=min_length)\n",
        "print(summary[0]['summary_text'])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5t7hUNE23uTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Question Answering\n",
        "#@markdown Question Answering is the task of extracting an answer from a text given a question\n",
        "question_answerer = pipeline(\"question-answering\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hPtRbaUI9-F1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **Answer**\n",
        "context = \"/content/ooo.txt\"  #@param {type:\"string\"}\n",
        "is_textfile = True  #@param {type:\"boolean\"}\n",
        "question = \"Who proposed the term Object-oriented ontology?\" #@param {type:\"string\"}\n",
        "\n",
        "if is_textfile:\n",
        "  if os.path.isfile(context):\n",
        "    with open(text, \"r\") as f:\n",
        "      sequence = f.read()\n",
        "else:\n",
        "  sequence = context\n",
        "\n",
        "result = question_answerer(question=question, context=sequence)\n",
        "\n",
        "clear_output()\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {result['answer']}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "yUZpkIgZ-aqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Text Generation\n",
        "#@markdown In text generation (a.k.a open-ended text generation) the goal is to create a coherent portion of text that is a continuation from the given context. The following example shows how GPT-2 can be used in pipelines to generate text.\n",
        "\n",
        "text_generator = pipeline(\"text-generation\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xtrrYPPQBxag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **Generate**\n",
        "prompt = \"Object-oriented ontology is\" #@param {type:\"string\"}\n",
        "max_length = 50 #@param {type:\"string\"}\n",
        "temperature = 1 #@param {type:\"slider\", min:0, max:2, step:0.1}\n",
        "\n",
        "text = text_generator(prompt, max_length=max_length, do_sample=True, temperature=temperature)\n",
        "\n",
        "clear_output()\n",
        "print(text[0]['generated_text'])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "VH34DkfkCJro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Machine Translation\n",
        "languages = \"translation_en_to_fr\" #@param [\"translation_en_to_fr\", \"translation_en_to_de\"]\n",
        "translator = pipeline(languages)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "tAqBuGVvDrr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Cultural practices and values are implicitly built into all computational systems\" #@param {type:\"string\"}\n",
        "max_length = 50 #@param {type:\"string\"}\n",
        "tr = translator(text, max_length=max_length)\n",
        "print(tr[0]['translation_text'])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ZLm5r_N4Enee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read more\n",
        "\n",
        "You can find more information at [huggingface](https://huggingface.co/) website:\n",
        "\n",
        "- [Docs](https://huggingface.co/docs)\n",
        "- [Pipelines](https://huggingface.co/docs/transformers/v4.19.2/en/main_classes/pipelines)\n",
        "\n",
        "Nice notebook about text generation with huggingface transformers and GPT (in Russian): [here](https://colab.research.google.com/drive/1sD_hQJOi3CrHn7Ba-XuKkHRToxDRRSof?usp=sharing)"
      ],
      "metadata": {
        "id": "16Ue4CY1GjtG"
      }
    }
  ]
}