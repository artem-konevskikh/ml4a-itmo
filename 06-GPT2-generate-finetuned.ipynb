{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "03-Current-GPT2-generate-finetuned.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNeXNKF6Zv59"
      },
      "source": [
        "# GPT-2 Text Generation Notebook\n",
        "\n",
        "Made by [Artem Konevskikh](https://aiculedssul.net/)\n",
        "\n",
        "Based on notebook by [Max Woolf](http://minimaxir.com). For more about `gpt-2-simple`, you can visit [this GitHub repository](https://github.com/minimaxir/gpt-2-simple)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VM69Hoc5j27B"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "-du42C9dZsEy"
      },
      "source": [
        "#@title Imports\n",
        "#@markdown By running this cell we are loading libraries needed to work with GPT2\n",
        "!pip install git+https://github.com/minimaxir/gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "3QNyS3GKlVZD"
      },
      "source": [
        "#@title Mounting Google Drive\n",
        "\n",
        "#@markdown Colab notebooks are Virtual Machines, so any data stored in it will be vanished as soon as we close it or reset it. So the best way to keep input data and save trained models is to mount your Google Drive and store it there.\n",
        "\n",
        "#@markdown After running this cell you will get the link, where you should grant the access to your Drive and copy auth token. Paste this token to the input below and press Enter\n",
        "\n",
        "gpt2.mount_gdrive()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgWDuRBNnMyu"
      },
      "source": [
        "## Text Generation\n",
        "\n",
        "In this notebook we will use the model you finetuned on your texts previously."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "vC5sZT3IdTOV"
      },
      "source": [
        "#@title Load a Finetuned Model Checkpoint\n",
        "\n",
        "#@markdown Running this cell will copy the `.rar` checkpoint file from your Google Drive into the Colaboratory VM.\n",
        "\n",
        "#@markdown **IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports.\n",
        "\n",
        "#@markdown Run name\n",
        "run_name='gpt-medialab-bbooo' #@param {type: \"string\"}\n",
        "gpt2.copy_checkpoint_from_gdrive(run_name=run_name)\n",
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name=run_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "k-9b2707geJ0"
      },
      "source": [
        "#@title Generation with the finetuned model\n",
        "#@markdown **Generation parameters**\n",
        "\n",
        "#@markdown Run name\n",
        "run_name= 'gpt-medialab-bbooo' #@param {type: \"string\"}\n",
        "\n",
        "#@markdown You can pass in a `prefix` to the generate function to force the text to start with a given character sequence and generate text from there\n",
        "prefix = 'The digital persona is' #@param {type: \"string\"}\n",
        "#@markdown Number of tokens to generate (default 1023, the maximum)\n",
        "length = 100  #@param {type:\"slider\", min:1, max:1023, step:1}\n",
        "#@markdown The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
        "temperature=0.7  #@param {type:\"slider\", min:0.1, max:1, step:0.1}\n",
        "#@markdown Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
        "top_k=0  #@param {type: \"number\"}\n",
        "#@markdown Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)\n",
        "top_p=0.9  #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "#@markdown Number of samples to generate\n",
        "nsamples=10  #@param {type: \"number\"}\n",
        "#@markdown Number of samples to generate in pararallel to speed up the process\n",
        "batch_size=5  #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "#@markdown Save samples to text file\n",
        "save_to_file = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "#@markdown *__Set parameters and  and run the cell to generate samples__*\n",
        "gen_file = 'gpt2_gentext_{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow()) if save_to_file else None\n",
        "gpt2.generate(sess,\n",
        "              run_name=run_name,\n",
        "              destination_path=gen_file,\n",
        "              prefix=None if prefix=='' else prefix,\n",
        "              length=length,\n",
        "              temperature=temperature,\n",
        "              top_k=int(top_k),\n",
        "              top_p=top_p,\n",
        "              nsamples=int(nsamples),\n",
        "              batch_size=batch_size\n",
        "              )"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-IpQoerrjdvz",
        "outputId": "8d7eac4f-c911-4268-a003-7ccefc51a1a2"
      },
      "source": [
        "#@markdown **Download newest generated file**\n",
        "if gen_file:\n",
        "  files.download(gen_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_7e637e6f-93ab-4efe-8479-e715c71ca6ee\", \"gpt2_gentext_20220213_175404.txt\", 4655)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}